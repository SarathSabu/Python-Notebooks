{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarathSabu/Python-Notebooks/blob/main/Word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n2QqmjC0esQ"
      },
      "source": [
        "Content in this notebook is modified from the [Word2Vec Application Tutorial](https://colab.research.google.com/drive/1X3XmmomQZrR-rPGbo_w6yydDbui86tzK)\n",
        "\n",
        "In this lecture, we go over basic operations on word vectors. There are many Natural Language Processing (NLP) libraries in Python, such as [NLTK](https://www.nltk.org/), [gensim](https://radimrehurek.com/gensim/), and [spaCy](https://spacy.io/). All of them have their own strength and focus. NLTK is one of the first comprehensive Python libraries for computational linguistics and has a big community. If you have worked on NLP, you probably have heard of it or used it. Gensim is a popular library for topic modeling. It also provides many functionalities similar to NLTK. It supports word embeddings and you can even train word embeddings using gensim. SpaCy is another popular NLP library and it provides built-in support for word vectors. We will use spaCy in this tutorial.  \\\\\n",
        "<br>\n",
        "You will learn:\n",
        "\n",
        "\n",
        "1.   Popular Python machine learning packages (spaCy, sklearn)\n",
        "2.   Calculating word similarity using Word2Vec model\n",
        "3.   Word analogy analysis\n",
        "4.   Calculating sentence similarity using Word2Vec model\n",
        "5.   Dimension reduction techniques for high-dimensional vectors\n",
        "6.   Visualizing Word2Vec in 2D space\n",
        "7.   Sentiment analysis using logistic regression and Word2Vec\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fymQg_Q068-"
      },
      "source": [
        "### Preliminary\n",
        "First, let's install the spaCy Python library and download their model for the English language. We only need to do it once. Then we can import the spaCy library and other useful libraries such as numpy (used for linear algebra and vector operations in Python). We can load our downloaded English model in our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VJCepyC9ZbX",
        "outputId": "09daca58-513e-432f-880b-169e7320b090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Only needs to be run once at the top of the notebook\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzPVan-OAIw8"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import spacy\n",
        "import numpy as np\n",
        "import csv\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn import linear_model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9wiQz4BAuQT"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_lg')  # load the English model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfpycYEG2T3y"
      },
      "source": [
        "### Word Similarity\n",
        "By representing words in vectors, we can use linear algebra and vector space models to analyze the relationship between words. One simple task is to calculate the cosine of two word vectors, namely the cosine similarity. This cosine similarity measures the semantic similarity of words. While the value ranges from -1 to 1, it is usually used in the non-negative space [0, 1] where 0 means 0 similarity and 1 means extremely similar or even identical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm-5ZI0gHp-w"
      },
      "source": [
        "In order to calculate the cosine similarity between words, we have to know their vector representations first, which are provided by the Word2Vec model. In the spaCy English model, these vector representations (pretrained using Word2Vec) are already provided. All we need to do is to retrieve these words from the spaCy English model and we will have access to these vector representations. \\\\\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-HL5bHMA3RE",
        "outputId": "711fbb74-d51b-49cc-aca6-c0633625dabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vector length: 300\n",
            "cat: [-0.15067   -0.024468  -0.23368   -0.23378   -0.18382    0.32711\n",
            " -0.22084   -0.28777    0.12759    1.1656    -0.64163   -0.098455\n",
            " -0.62397    0.010431  -0.25653    0.31799    0.037779   1.1904\n",
            " -0.17714   -0.2595    -0.31461    0.038825  -0.15713   -0.13484\n",
            "  0.36936   -0.30562   -0.40619   -0.38965    0.3686     0.013963\n",
            " -0.6895     0.004066  -0.1367     0.32564    0.24688   -0.14011\n",
            "  0.53889   -0.80441   -0.1777    -0.12922    0.16303    0.14917\n",
            " -0.068429  -0.33922    0.18495   -0.082544  -0.46892    0.39581\n",
            " -0.13742   -0.35132    0.22223   -0.144     -0.048287   0.3379\n",
            " -0.31916    0.20526    0.098624  -0.23877    0.045338   0.43941\n",
            "  0.030385  -0.013821  -0.093273  -0.18178    0.19438   -0.3782\n",
            "  0.70144    0.16236    0.0059111  0.024898  -0.13613   -0.11425\n",
            " -0.31598   -0.14209    0.028194   0.5419    -0.42413   -0.599\n",
            "  0.24976   -0.27003    0.14964    0.29287   -0.31281    0.16543\n",
            " -0.21045   -0.4408     1.2174     0.51236    0.56209    0.14131\n",
            "  0.092514   0.71396   -0.021051  -0.33704   -0.20275   -0.36181\n",
            "  0.22055   -0.25665    0.28425   -0.16968    0.058029   0.61182\n",
            "  0.31576   -0.079185   0.35538   -0.51236    0.4235    -0.30033\n",
            " -0.22376    0.15223   -0.048292   0.23532    0.46507   -0.67579\n",
            " -0.32905    0.08446   -0.22123   -0.045333   0.34463   -0.1455\n",
            " -0.18047   -0.17887    0.96879   -1.0028    -0.47343    0.28542\n",
            "  0.56382   -0.33211   -0.38275   -0.2749    -0.22955   -0.24265\n",
            " -0.37689    0.24822    0.36941    0.14651   -0.37864    0.31134\n",
            " -0.28449    0.36948   -2.8174    -0.38319   -0.022373   0.56376\n",
            "  0.40131   -0.42131   -0.11311   -0.17317    0.1411    -0.13194\n",
            "  0.18494    0.097692  -0.097341  -0.23987    0.16631   -0.28556\n",
            "  0.0038654  0.53292   -0.32367   -0.38744    0.27011   -0.34181\n",
            " -0.27702   -0.67279   -0.10771   -0.062189  -0.24783   -0.070884\n",
            " -0.20898    0.062404   0.022372   0.13408    0.1305    -0.19546\n",
            " -0.46849    0.77731   -0.043978   0.3827    -0.23376    1.0457\n",
            " -0.14371   -0.3565    -0.080713  -0.31047   -0.57822   -0.28067\n",
            " -0.069678   0.068929  -0.16227   -0.63934   -0.62149    0.11222\n",
            " -0.16969   -0.54637    0.49661    0.46565    0.088294  -0.48496\n",
            "  0.69263   -0.068977  -0.53709    0.20802   -0.42987   -0.11921\n",
            "  0.1174    -0.18443    0.43797   -0.1236     0.3607    -0.19608\n",
            " -0.35366    0.18808   -0.5061     0.14455   -0.024368  -0.10772\n",
            " -0.0115     0.58634   -0.054461   0.0076487 -0.056297   0.27193\n",
            "  0.23096   -0.29296   -0.24325    0.10317   -0.10014    0.7089\n",
            "  0.17402   -0.0037509 -0.46304    0.11806   -0.16457   -0.38609\n",
            "  0.14524    0.098122  -0.12352   -0.1047     0.39047   -0.3063\n",
            " -0.65375   -0.0044248 -0.033876   0.037114  -0.27472    0.0053147\n",
            "  0.30737    0.12528   -0.19527   -0.16461    0.087518  -0.051107\n",
            " -0.16323    0.521      0.10822   -0.060379  -0.71735   -0.064327\n",
            "  0.37043   -0.41054   -0.2728    -0.30217    0.015771  -0.43056\n",
            "  0.35647    0.17188   -0.54598   -0.21541   -0.044889  -0.10597\n",
            " -0.54391    0.53908    0.070938   0.097839   0.097908   0.17805\n",
            "  0.18995    0.49962   -0.18529    0.051234   0.019574   0.24805\n",
            "  0.3144    -0.29304    0.54235    0.46672    0.26017   -0.44705\n",
            "  0.28287   -0.033345  -0.33181   -0.10902   -0.023324   0.2106\n",
            " -0.29633    0.81506    0.038524   0.46004    0.17187   -0.29804  ]\n"
          ]
        }
      ],
      "source": [
        "# retrieve words from the English model vocabulary\n",
        "cat = nlp.vocab['cat']\n",
        "dog = nlp.vocab['dog']\n",
        "car = nlp.vocab['car']\n",
        "\n",
        "# print the dimension of word vectors\n",
        "print('vector length:', len(cat.vector))\n",
        "\n",
        "# print the word vector\n",
        "print('cat:', cat.vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmpDwypeHSIy"
      },
      "source": [
        "Try to retrieve some other words and check if they have the same dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NO5S4yX9hgZg",
        "outputId": "4ef86e9d-6aa8-4f81-ee75-e92cc44e78ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ],
      "source": [
        "computer = nlp.vocab['computer']\n",
        "print(len(computer.vector))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g5mO0AfIT94"
      },
      "source": [
        "After retrieving the words and their vector representations, we can use the built-in similarity function (which implements cosine similarity) to calculate word similarity based on these vectors. Is 'cat' more similar to 'dog' than 'car'? Can you find some properties of cosine similarity?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpxnslv1DB7e",
        "outputId": "80f612ae-d0d5-4d9d-ea73-1abe2af1327a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The similarity between cat and cat: 1.0\n",
            "The similarity between cat and dog: 0.8016854524612427\n",
            "The similarity between dog and cat: 0.8016854524612427\n",
            "The similarity between cat and car: 0.3190753161907196\n",
            "The similarity between dog and car: 0.35629159212112427\n"
          ]
        }
      ],
      "source": [
        "# you can calculate the similarity between words using\n",
        "# the built-in 'similarity' function\n",
        "print('The similarity between cat and cat:', cat.similarity(cat))\n",
        "print('The similarity between cat and dog:', cat.similarity(dog))\n",
        "print('The similarity between dog and cat:', dog.similarity(cat))\n",
        "print('The similarity between cat and car:', cat.similarity(car))\n",
        "print('The similarity between dog and car:', dog.similarity(car))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe1G8CvuIxIP"
      },
      "source": [
        "Now let's try some other words. Also, try to calculate the cosine similarity between 'hotel' and 'motel' and the cosine similarity between 'hotel' and 'hospital'. Which one is more similar to 'hotel'? 'motel' or 'hospital'?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QALZbd0Jhjlf",
        "outputId": "c6739498-515a-4ec0-eca7-30ae452db349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7404688596725464\n",
            "0.38639551401138306\n"
          ]
        }
      ],
      "source": [
        "# calculate the similarity of your own words using the built-in function\n",
        "hotel = nlp.vocab['hotel']\n",
        "motel = nlp.vocab['motel']\n",
        "hospital = nlp.vocab['hospital']\n",
        "\n",
        "# what is the similarity between (hotel, motel) and (hotel, hospital)\n",
        "print(hotel.similarity(motel))\n",
        "print(hotel.similarity(hospital))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma4PgQeaMZfM"
      },
      "source": [
        "Now we know how to compare the similarity of two words using pretrained Word2Vec model. We can also use it to help us find semantically similar words, that is given a word retrieve similar words from the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hte91o_E92gd"
      },
      "source": [
        "Following, let's try to find the most semantically similar word from a list of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Tnu7AU-99gt"
      },
      "outputs": [],
      "source": [
        "# Define a function to find the most similar word\n",
        "def most_similar_word(target_word, word_list):\n",
        "    target_token = nlp(target_word)\n",
        "\n",
        "    if not target_token.has_vector:\n",
        "        print(f\"Warning: '{target_word}' does not have a word vector in en_core_web_sm.\")\n",
        "        return None\n",
        "\n",
        "    max_similarity = -1\n",
        "    most_similar = None\n",
        "\n",
        "    for word in word_list:\n",
        "        token = nlp(word)\n",
        "        if token.has_vector:  # Ensure the word has a vector representation\n",
        "            similarity = target_token.similarity(token)\n",
        "            if similarity > max_similarity:\n",
        "                max_similarity = similarity\n",
        "                most_similar = word\n",
        "    return most_similar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEW9t-uQ_JF9",
        "outputId": "d1790cc4-8a42-4e06-ae5f-26ba82c03de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar word to 'puppy' is 'puppies'.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "word_list = [\"dog\", \"cat\", \"fish\", \"apple\", \"car\", \"puppies\", \"pet\"]\n",
        "target = \"puppy\"\n",
        "similar_word = most_similar_word(target, word_list)\n",
        "\n",
        "print(f\"The most similar word to '{target}' is '{similar_word}'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYclgBII2gc7"
      },
      "source": [
        "### Word Analogy\n",
        "One interesting finding for the Word2Vec model is that it embeds some analogical relationships between words. \\\\\n",
        "<br>\n",
        "*Man is to Woman as King is to Queen* \\\\\n",
        "Man - Woman = King - Queen \\\\\n",
        "<br>\n",
        "*Paris is to France as Madrid is to Spain* \\\\\n",
        "Paris - France = Madrid - Spain \\\\\n",
        "<br>\n",
        "These relationships can be reconstructed using word embeddings. \\\\\n",
        "<br>\n",
        "![analogy](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/06/06062705/Word-Vectors.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6Xo9Prcfpoy"
      },
      "outputs": [],
      "source": [
        "# word analogy example\n",
        "# king is to man as what is to woman?\n",
        "king = nlp.vocab['king']\n",
        "man = nlp.vocab['man']\n",
        "woman = nlp.vocab['woman']\n",
        "\n",
        "# resulting vector\n",
        "result = king.vector - man.vector + woman.vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg_R5y2MyWFv",
        "outputId": "63635a53-157e-4163-fbe7-839ac7f60dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between queen and result: [[0.78808445]]\n"
          ]
        }
      ],
      "source": [
        "# what word does the 'result' vector closely correspond to?\n",
        "queen = nlp.vocab['queen']\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print('Similarity between queen and result:', cosine_similarity(result.reshape(1, -1), queen.vector.reshape(1, -1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHDhFaO2VaFJ"
      },
      "source": [
        "Let's try: \\\\\n",
        "Paris - France = Madrid - Spain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unaXunKv0Y0F",
        "outputId": "dd95507d-d5b6-4656-f094-b39e9c312f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between queen and result: [[0.7725211]]\n"
          ]
        }
      ],
      "source": [
        "# another example\n",
        "# Paris is to France as Madrid is to what?\n",
        "Paris = nlp.vocab['Paris']\n",
        "France = nlp.vocab['France']\n",
        "Madrid = nlp.vocab['Madrid']\n",
        "maybe_Spain = France.vector - Paris.vector + Madrid.vector\n",
        "Spain = nlp.vocab['Spain']\n",
        "\n",
        "\n",
        "print('Similarity between queen and result:', cosine_similarity(maybe_Spain.reshape(1, -1), Spain.vector.reshape(1, -1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFPYDPuX6thm"
      },
      "source": [
        "### Sentence/Document Level Similarity\n",
        "Using word embeddings, we can also calculate similarity between sentences and documents. More advanced models such as Doc2Vec or neural networks can be used, but in this tutorial we will continue to use Word2Vec model to calculate document similarity. Since sentences and documents are composed of words, one easy way to obtain vector representations for sentences/documents is to calculate the average vectors of words. \\\\\n",
        "<br>\n",
        "Let's try to calculate the similarity among these three sentences:\n",
        "\n",
        "\n",
        "1. \"The dog is playing in the park.\"\n",
        "2. \"A puppy is having fun at the playground.\"\n",
        "3. \"The car is parked near the shopping mall.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiS9WQyG8zqG",
        "outputId": "99542659-d6d9-426d-be8d-c3b8134563b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between s1 and s2: [0.9069085]\n",
            "Similarity between s1 and s3: [0.82167923] \n",
            "\n",
            "Similarity between s1 and s2: 0.9069085121154785\n",
            "Similarity between s2 and s3: 0.8216792345046997\n"
          ]
        }
      ],
      "source": [
        "# Word2Vec model does not provide vector representations for sentences\n",
        "# or documents. How is the similarity between sentences computed?\n",
        "# Since sentences are composed of words, an easy way to obtain the vector\n",
        "# representations of sentences is by averaging the vectors of each word in\n",
        "# the sentence.\n",
        "\n",
        "s1 = 'The dog is playing in the park.'\n",
        "s2 = 'A puppy is having fun at the playground.'\n",
        "s3 = 'The car is parked near the shopping mall.'\n",
        "sent_list = [s1, s2, s3]\n",
        "\n",
        "corpus_vec = []\n",
        "for sent in sent_list:\n",
        "    # nlp(sent) performs several steps to \"sent\"\n",
        "    # First, it splits the sentence into individual tokens (words, punctuations, etc.)\n",
        "    # Part-of-speech tagging, assigns a grammatical category (e.g., noun, verb, etc.) to each token\n",
        "    # Dependency parsing -- analyze the syntactic structure and establish relationships between words.\n",
        "    # Named entity recognition\n",
        "    # Lemmatization -- reduce words to their base form (e.g., running --> run)\n",
        "    # Vectorization (if available) -- assigns word embeddings if the word exists in the model\n",
        "    doc = nlp(sent)\n",
        "    sent_vec = []\n",
        "    for token in doc:\n",
        "        ## print(token.text)\n",
        "        sent_vec += [token.vector]\n",
        "    sent_vec = np.mean(sent_vec, axis=0)\n",
        "    corpus_vec.append(sent_vec)\n",
        "\n",
        "\n",
        "print('Similarity between s1 and s2:', cosine_similarity(corpus_vec[0].reshape(1, -1), corpus_vec[1].reshape(1, -1))[0])\n",
        "print('Similarity between s1 and s3:', cosine_similarity(corpus_vec[0].reshape(1, -1), corpus_vec[2].reshape(1, -1))[0], '\\n')\n",
        "\n",
        "# Spacy can automatically construct sentence embedding by average the word embeddings.\n",
        "sent_1 = nlp(s1)\n",
        "sent_2 = nlp(s2)\n",
        "sent_3 = nlp(s3)\n",
        "\n",
        "print('Similarity between s1 and s2:', sent_1.similarity(sent_2))\n",
        "print('Similarity between s2 and s3:', sent_1.similarity(sent_3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QPAmCbTLr-3",
        "outputId": "06e0c0ee-f11b-41f6-8c34-72d0b0579c6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between s1 and s2: 0.8482343554496765\n",
            "Similarity between s2 and s3: 0.6506569385528564\n"
          ]
        }
      ],
      "source": [
        "# While the sentence embeddings reveal that s1 is more similar to s2 than to s3, the similarity score between s2 and s3 is still high.\n",
        "# What could be the reason?\n",
        "\n",
        "sent_1 = nlp(s1)\n",
        "sent_2 = nlp(s2)\n",
        "sent_3 = nlp(s3)\n",
        "\n",
        "sent_1_no_stop = nlp(' '.join([str(t) for t in sent_1 if not t.is_stop]))\n",
        "sent_2_no_stop = nlp(' '.join([str(t) for t in sent_2 if not t.is_stop]))\n",
        "sent_3_no_stop = nlp(' '.join([str(t) for t in sent_3 if not t.is_stop]))\n",
        "\n",
        "print('Similarity between s1 and s2:', sent_1_no_stop.similarity(sent_2_no_stop))\n",
        "print('Similarity between s2 and s3:', sent_1_no_stop.similarity(sent_3_no_stop))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRJxWYXTNw6_"
      },
      "source": [
        "Removing stopwords increases the difference in the two similarity scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYs9_tHSFBhd"
      },
      "source": [
        "### Word Embeddings Visualization\n",
        "Since the word vectors we use have 300 dimensions, we cannot visualize them. One natural way is to apply dimension reduction first and then visualize them. We use a popular dimension reduction technique called PCA (Principal Component Analysis) to reduce the word vectors to 2D and then plot the words in our word analogy example to see if we can find some pattern visually. \\\\\n",
        "<br>\n",
        "An interactive visualization of word embeddings can be found here: \\\\\n",
        "[https://projector.tensorflow.org/](https://projector.tensorflow.org/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "data = np.array([king.vector, man.vector, queen.vector, woman.vector])\n",
        "\n",
        "# Principla component analysis is a dimensionality reduction technique that transforms\n",
        "# data into a new coordinate system, where the axes are orthogonal and represent the\n",
        "# directions of maximum variance in the original data.\n",
        "# This allows for simplifying datasets while retaining important information and making\n",
        "# data easier to visualize and analyze.\n",
        "\n",
        "pca = PCA(n_components= 2)\n",
        "word_vectors_reduced = pca.fit_transform(data)  # Shape: (num_words, target_dim)\n",
        "\n",
        "print(word_vectors_reduced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-tzaOdCL1Y2",
        "outputId": "79325905-0e91-4ae8-b77a-47327c019359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.7271984  2.1668932]\n",
            " [ 3.212085   2.148608 ]\n",
            " [-3.2678554 -2.482027 ]\n",
            " [ 3.782969  -1.8334746]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the 2d vectors and show their labels\n",
        "plt.scatter(data[:, 0], data[:, 1], s=100)\n",
        "labels = ['king', 'man', 'queen', 'woman']\n",
        "\n",
        "for i, txt in enumerate(labels):\n",
        "    plt.annotate(txt, (data[i,0], data[i,1]), xytext=(2, 3), textcoords='offset points')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "znaUso8rMD4s",
        "outputId": "d3090f10-ab4f-4384-b787-1e455cfb43dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXzQ0M-OW0h0"
      },
      "source": [
        "### Sentiment Analysis\n",
        "The major reason for coming up with word embedding models is that we want to use these embeddings which encode the word semantics to help us tackle problems related with natural language. \\\\\n",
        "<br>\n",
        "One such task is sentiment analysis. By analyzing the sentiment of texts, we want to understand whether a given sentence/document is positive or negative. For example, 'the weather is so nice today' has a positive sentiment whereas 'he is bored by the movie' has a negative sentiment. \\\\\n",
        "<br>\n",
        "In this tutorial, we want to use the word embeddings combined with a simple machine learning model ([logistic regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)) to do sentiment analysis. Logistic regression is a linear classification model and in our case we want to classify whether a given sentence is positive or negative. So it's a binary classification. \\\\\n",
        "<br>\n",
        "![logistic](https://rasbt.github.io/mlxtend/user_guide/classifier/SoftmaxRegression_files/logistic_regression_schematic.png)\n",
        "<br>\n",
        "Our training data contains 2,748 from Yelp reviews, IMDB movie reviews, and Amazon reviews. In the dataset, 1 means positive and 0 means negative. The original data can be downloaded from [here](https://www.kaggle.com/rahulin05/sentiment-labelled-sentences-data-set/data), the combined file can be downloaded from [here](https://drive.google.com/file/d/1knrjvDNkiXtviXBoLm5OJY45_kcCmDxe/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "8LliIw9nW4Fc",
        "outputId": "c50f1230-c703-4703-dbfe-18b8ae09d3b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c7f9d788-5eea-4951-9879-e7b471f1762c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c7f9d788-5eea-4951-9879-e7b471f1762c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving combined_training.txt to combined_training.txt\n"
          ]
        }
      ],
      "source": [
        "# load files into the environment\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGWb5845wEZZ",
        "outputId": "7a2450ec-f466-4428-c19c-413568889f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2748\n",
            "[\"Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check.\", 0]\n"
          ]
        }
      ],
      "source": [
        "# read data\n",
        "data_raw = []\n",
        "with open('combined_training.txt', newline='') as fr:\n",
        "    reader = csv.reader(fr, delimiter='\\t')\n",
        "    for row in reader:\n",
        "        data_raw.append([row[0], int(row[1])])\n",
        "\n",
        "# print the number of data\n",
        "print(len(data_raw))\n",
        "\n",
        "# print the last data item\n",
        "print(data_raw[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U9GGTwFzTnE",
        "outputId": "1603102c-a853-462e-a374-a7880db5b598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2748, 300)\n",
            "(2748,)\n",
            "Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check. 0\n"
          ]
        }
      ],
      "source": [
        "x_train = np.array([nlp(d[0]).vector for d in data_raw])\n",
        "y_train = np.array([d[1] for d in data_raw])\n",
        "\n",
        "# print the dimension of x\n",
        "print(x_train.shape)\n",
        "\n",
        "# print the dimension of y\n",
        "print(y_train.shape)\n",
        "\n",
        "# double check\n",
        "print(nlp(data_raw[-1][0]).text, y_train[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "VwSJnk0A15LB",
        "outputId": "0b5c5a65-ddb7-4f87-c9f5-2cf6088cc350"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "logreg = linear_model.LogisticRegression()\n",
        "logreg.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTXDcQRq2JHF",
        "outputId": "3a010e86-1349-4394-ed66-35f56fb31192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0]\n"
          ]
        }
      ],
      "source": [
        "# predict using trained model\n",
        "predict = logreg.predict(np.array([nlp('the weather yesterday is good').vector, nlp('the food in this restaurant is below my expectation').vector]))\n",
        "print(predict)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}